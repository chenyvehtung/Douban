## 豆瓣TOP250 Scrapy爬虫

一个简单的[豆瓣Top250](https://movie.douban.com/top250)的Python Scrapy爬虫。这是整个完整项目的一个独立子模块，用于自动爬取并生成应用的数据库以及对应的图像。

### 运行方法
配置好[scrapy环境](http://scrapy.readthedocs.io/en/latest/intro/install.html)，然后运行如下命令：

```sh
scrapy crawl douban
```

### 获取数据

* 电影封面数据，存放于`movie_poster`文件夹下，命名方式为”电影排名.jpg“
* 电影相关基础数据，包括电影排名，名称，导演，主演(前5个)，得分，发行时间，类型，简介(完整版)，存放在`doubanmovie.sqlite`中

### 关于爬虫

* 名字： douban
* 最大并行请求： 10个
* 下载延时： 10s

由于豆瓣存在反爬虫机制，爬取太快会被限制。所以只能做这样的策略，不过爬取时间会相对较长，好在数据不多。

### 存在问题

对于某些电影页面，爬虫爬取时会极个别响应出现**404 Not Found**的错误，但直接在浏览器中打开却没有任何问题，我做了如下一些解决的尝试：

* 对于每个请求，动态变化User-Agent，详见*douban/middlewares.py*
* 激活retry download的middleware， 对于返回404的页面，做5次尝试，详见*douban/settings.py*
* 添加Twisted的exception处理函数，尝试是否可以接受到有抛出来的exception

但是最后都没有成功。所以只好使用折中的方案，引入记录机制。在爬虫结束打印状态时，输出没有成功爬取的链接及其对应的状态码，同时记录到文件*douban/failed_rsps.log*中，然后就只好根据链接手动抓取数据存到数据库中了。

### 其他

爬虫的保存数据库比较奇怪，主要的目的其实是为了适应之前写的这个小项目。这个Win8的应用是一年前写的，当时的数据是手工复制粘贴的……对于数据库了解也不多，所以安排得很不合理。     
当时确实也尝试过使用Scrapy，失败告终，可怜那时干了好多体力后。Anyhow，突然想起这件事，就花了点时间弥补了这点小遗憾。       
豆瓣的反爬虫机制做得确实不错，对于当时几乎不懂Python的我来说，想在两天内上手Scrapy并成功爬取数据，真的不可能。
